<!DOCTYPE HTML>
<!--
	Template Provided By:
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Final EAS 510 Project - Qiuxing Chen </title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Sidebar -->
			<section id="sidebar">
				<div class="inner">
					<nav>
						<ul>
							<li><a href="#intro">Final Movie Genre Project</a></li>
							<li><a href="#one">Introduction & Objectives</a></li>
							<li><a href="#two">Dataset Description</a></li>
							<li><a href="#three">Methodology (Text)</a></li>
							<li><a href="#four">Results & Evaluation</a></li>
							<li><a href="#five">Reproducibility & Instructions</a></li>
						</ul>
					</nav>
				</div>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Intro -->
					<section id="intro" class="wrapper style1 fullscreen fade-up">
						<div class="inner">
							<h1>Final EAS 510 Project - Qiuxing Chen</h1>
							<p>This is a fine responsive site template that I will use for my project, designed by <a href="http://html5up.net">HTML5 UP</a><br />
							and released for free under the <a href="http://html5up.net/license">Creative Commons</a>.</p>

							<p>I am an Engineering Education PhD student, and do not have any Data Science and Computer Science background so a lot of this was very new to me (and I gave my best attempt at this with the time and knowledge I had). My group project partner also dropped out of the class, so there is no vision aspect of this project. I tried my best with the Data gathering & exploration, though it is still unbalanced. The NLP text models I implemented are RNN and BERT (uncased). I referenced many Medium.com articles and other documentation for this (including PyTorch and Pandas). I also referenced the class notes that are posted on the course website for batching and training loops.
							</p>
							
						</div>
					</section>

				<!-- One -->
					<section id="one" class="wrapper style2 spotlights">
						<section>
							<div class="content">
								<div class="inner">
									<h2>Introduction & Objectives</h2>
									<p>	The goal of the multi-modal movie genre classifier is to identify movies for specified genres. Most movies have multiple genres, so it would be useful to apply muli-label classification on plot summaries/overviews. This project only has the NLP (text-implementation) as my group partner was responsible for the visionmodel aspect of the project. The objectives in this project include: </p>
									<ul>
										<li>Data Handling & Pre-processing</li>
										<li>Modeling Approaches (Text)</li>
										<li>Evaluation</li>
										<li>Optimization</li>
									</ul>
								</div>
							</div>
						</section>

				<!-- Two -->
					<section id="two" class="wrapper style3 fade-up">
						<div class="inner">
							<h2>Dataset Description</h2>
							<p>The original dataset is from "Letterboxd (Movies Dataset)" by Simon Garanin from Kaggle.com and is sourced from GPL3 (https://www.gnu.org/licenses/gpl-3.0.en.html). As I am deploying this via GitHub Pages, it counts as distribution. The amount of data cleaned up (removing N/A, fill out genres, etc.) amounts to 27068 movies. The distribution of the original dataset is seen below: </p>
							<img src="images/Distribution-of-Movie-Genres.png" alt="Movie Genres", width= 1000, height = 1000>

							<p>Supplemental data is from TMDB (as specified by TMDB API Attribution page, the logo is included below for the use of their data). </p>
							<img src="images/TMDB-Credit-Logo.png" alt="TMDB Credit", width= 300, height = 300>

							<div class="features">
								<section>
									<span class="icon solid major fa-code"></span>
									<h3>Data Distribution (Genres)</h3>
									<p>The genres in the dataset are: Action, Comedy, Adventure, Thriller, Drama, Science Fiction, Music, Romance, History, Crime, Animation, Mystery, Horror, Fantasy, War, Western, TV Movie, Documentary.</p>
								</section>
								<section>
									<span class="icon solid major fa-lock"></span>
									<h3>Unbalanced Data</h3>
									<p>Observation of the distribution of datasets show that the data is highly unbalanced, with the most prevalent genres being Drama & Comedy. The least represented genres are Western, TV Movie, War, History, Music, and Family. I attempted to correct this by using supplemental data from TMDB on the specified underrepresented genres. The Gaussian distribution of the original dataset is shown below: </p>
									<img src="images/original_gauss.png" alt="Original Dataset Gaussian Distribution", width= 500, height = 500>

									<p>The cleaned csv's (genre and movies) are then uploaded to a Kaggle account for me to pull the data using Kaggle's API. The id's in both csv's are utilized to create a movie dictionary where the ID is matched to the genres. The values in the dictionary were used to create a co-occurence matrix. For movies that had more than two genres, I used itertool's permutations and python frozenset and looped the dictionary to remove any duplicates (for example, "Action, Comedy" and "Comedy, Action" are duplicates). The values are converted into a pandas dataframe and plotted with Seaborn Heatmap. </p>
								</section>
								<section>
									<span class="icon solid major fa-cog"></span>
									<h3>Co-Occurrence Matrix</h3>
									<p>Pictured below is the co-occurrence matrix for the movie genres. By inspection, the highest combinations are with (Comedy, Drama), (Drama, Romance), and (Drama, Thriller). The lowest combinations are (Documentary, Western), (Documentary, Thriller), and (History, Science Fiction).</p>
									<img src="images/Co-Occurrence-Matrix-of-Movie-Genres.png" alt="Co-Occurrence Matrix", width= 1000, height = 1000>
								</section>
								<section>
									<span class="icon solid major fa-link"></span>
									<h3>Dataset Balancing</h3>
									<p>After gathering the data, I attempted to balance the data in two ways. The first was simply finding more data (done through TMDB) and appended it to the existing Pandas dataframe that I had with the data from the original dataset (data increase of 400). This has only slightly increased the presence of the underrepresented genres, as shown in the barplot and Gaussian distribution below: </p>
									<img src="images/Distribution-of-Movie-Genres-(with-more-data).png" alt="More Data Distribution of Movies", width= 1000, height = 1000>
									<img src="images/second_gauss.png" alt="Second Dataset Gaussian Distribution", width= 500, height = 500>
									<p>This did not fully balance the data, so I applied random undersampling to the overrepresented data and upsampling to the underrepresented data as recommended by recent sources such as Medium.com and Google for Developers</p>
									<ul class="actions">
								<li><a href="https://developers.google.com/machine-learning/crash-course/overfitting/imbalanced-datasets" class="button">Google for Developers Machine Learning Datasets: Imbalanced Datasets</a></li>
								<li><a href="https://medium.com/@tam.tamanna18/handling-imbalanced-datasets-in-python-methods-and-procedures-7376f99794de" class="button">Medium.com Handling Imbalanced Datasets in Python: Methods and Procedures</a></li>
							</ul>
								</section>
								<section>
									<span class="icon major fa-gem"></span>
									<h3>Text Preprocessing</h3>
									<p>The data is in the form of a pandas dataframe and has columns "description" and "genres". These genre labels are passed through Scikit's MultiLabel Binarizer and trainsformed, which converted them into a Numpy array of 1's and 0's. Some minor dataframe editing was done in order to ensure that the columns were "descriptions" and "genres" (or the category of genres) and not the index.</p>
									<p>NLTK packages "punkt", "stopwords", and "punkt_tab" were called to remove stopwords such as "the", "a", etc. that did not contribute much to understanding the text (compared to keywords).</p>
								</section>
							</div>
							
						</div>
					</section>

				<!-- Three -->
					<section id="three" class="wrapper style1 fade-up">
						<div class="inner">
							<h2>Methodology (Text)</h2>
							<h3>Text Pre-processing</h3>
							<p>I spent a significant amount of time on this section in the beginning of the semester and used Bag of Words and passing the data through NLTK loops to remove unnecessary details like stop words, numbers and symbols. This method turned out to be incorrect (as noted in the presentation in April) and I restarted the whole process from scratch with Tokenizer and BERT Tokenizer.</p>
							<h4>Tokenization</h4>
							<p>Tokenization is converting the text into smaller sequences and parts (known as tokens). For example, a text "A brown fox jumped over a bush" will be converted into ["A", "brown", "fox", "jumped", "over", "a", "bush"] and I passed my descriptions into Tensorflow keras Tokenizer for the RNN Model. I utilized post padding (adding zeros to the end of sequence) in order to make the sequences uniform in size. This is an important step as sequences of different sizes will lead to errors. Post padding is also preferred in transformer models.</p>
							<ul>
								<li><a href="https://www.tensorflow.org/guide/keras" class="button"> Keras Tensorflow </a></li>
								<li><a href="https://saadsohail5104.medium.com/understanding-padding-in-nlp-types-and-when-to-use-them-bacae6cae401#:~:text=Types%20of%20Padding%20in%20NLP&text=Pre%2DPadding%20(Default)%3A,the%20end%20of%20a%20sequence." class="button"> Medium.com Understanding padding in NLP </a></li>
							</ul>

							<p>In the RNN Model, I referenced the PyTorch article "NLP From Scratch: Classifying Names with a Character-Level RNN" by Sean Robertson and modified his model with embedded dimensions and batching. Sigmoid activation functions were included in the class for non-linearity and is useful in this case as the genre labels were binarized using Multilabel Binarizer. The outputs of this sigmoid activation function would fall between 0 and 1. If I had not done so, a softmax activation function would be more appropriate as it would be a multi-class classification problem. For the embedding dimension, torch.nn.Embedding was utilized to store the word embeddings and indices. A linear activation function was applied to the hidden and output sizes (self.h2o) in combination with the non-linear activation function in order to enhance the model's learning and prediction. This is the hidden layer activation.</p>

							<p>For BERT, I utilized the BERT Tokenizer that came with the HuggingFace BERT uncased transformer package. I used truncation to remove elements that exceed the length of the specified maximum length (which was based on the description length). Attention masks were employed using BERT's encoder plus function. The IDs, attention masks, and labels were then batched for training and testing.</p>
							<ul>
								<li><a href="https://medium.com/@piyushkashyap045/guide-to-tokenization-and-padding-with-bert-transforming-text-into-machine-readable-data-5a24bf59d36b" class="button"> Medium.com Guide to Tokenization and Padding with BERT: Transforming Text into Machine-Readable Data </a></li>
							</ul>
							<ul>
								<li><a href="generic.html" class="button">Learn more</a></li>
							</ul>
						</div>
					</section>

				<!-- Four -->
					<section id="four" class="wrapper style3 fade-up">
						<div class="inner">
							<h2>Results & Evaluation</h2>
							<p>Phasellus convallis elit id ullamcorper pulvinar. Duis aliquam turpis mauris, eu ultricies erat malesuada quis. Aliquam dapibus, lacus eget hendrerit bibendum, urna est aliquam sem, sit amet imperdiet est velit quis lorem.</p>
							<div class="features">
								<section>
									<span class="icon solid major fa-code"></span>
									<h3>Lorem ipsum amet</h3>
									<p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p>
								</section>
								<section>
									<span class="icon solid major fa-lock"></span>
									<h3>Aliquam sed nullam</h3>
									<p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p>
								</section>
								<section>
									<span class="icon solid major fa-cog"></span>
									<h3>Sed erat ullam corper</h3>
									<p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p>
								</section>
								<section>
									<span class="icon solid major fa-desktop"></span>
									<h3>Veroeros quis lorem</h3>
									<p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p>
								</section>
								<section>
									<span class="icon solid major fa-link"></span>
									<h3>Urna quis bibendum</h3>
									<p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p>
								</section>
								<section>
									<span class="icon major fa-gem"></span>
									<h3>Aliquam urna dapibus</h3>
									<p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p>
								</section>
							</div>
							<ul class="actions">
								<li><a href="generic.html" class="button">Learn more</a></li>
							</ul>
						</div>
					</section>
				<!-- Five -->
					<section id="five" class="wrapper style3 fade-up">
						<div class="inner">
							<h2>Reproducibility & Instructions</h2>
							<p>Phasellus convallis elit id ullamcorper pulvinar. Duis aliquam turpis mauris, eu ultricies erat malesuada quis. Aliquam dapibus, lacus eget hendrerit bibendum, urna est aliquam sem, sit amet imperdiet est velit quis lorem.</p>
							<div class="features">
								<section>
									<span class="icon solid major fa-code"></span>
									<h3>Lorem ipsum amet</h3>
									<p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p>
								</section>
								<section>
									<span class="icon solid major fa-lock"></span>
									<h3>Aliquam sed nullam</h3>
									<p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p>
								</section>
								<section>
									<span class="icon solid major fa-cog"></span>
									<h3>Sed erat ullam corper</h3>
									<p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p>
								</section>
								<section>
									<span class="icon solid major fa-desktop"></span>
									<h3>Veroeros quis lorem</h3>
									<p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p>
								</section>
								<section>
									<span class="icon solid major fa-link"></span>
									<h3>Urna quis bibendum</h3>
									<p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p>
								</section>
								<section>
									<span class="icon major fa-gem"></span>
									<h3>Aliquam urna dapibus</h3>
									<p>Phasellus convallis elit id ullam corper amet et pulvinar. Duis aliquam turpis mauris, sed ultricies erat dapibus.</p>
								</section>
							</div>
							<ul class="actions">
								<li><a href="generic.html" class="button">Learn more</a></li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper style1-alt">
				<div class="inner">
					<ul class="menu">
						<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>